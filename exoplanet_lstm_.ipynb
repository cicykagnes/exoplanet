{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exoplanet_lstm .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5KWcOyMqxaj",
        "outputId": "923dae50-7603-4a56-89ef-7da9c4bf96ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "youYqtLcrLDs",
        "outputId": "571154b1-2a2c-4a42-ee3f-a5299460813c"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s26Mc59hVWo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.filters import uniform_filter1d, gaussian_filter\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
        "                            confusion_matrix, fbeta_score, precision_recall_curve, \\\n",
        "                            average_precision_score, auc\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten,Input,  Activation\n",
        "from keras.models import load_model, Model,Sequential,model_from_json\n",
        "from keras.layers import LSTM, Reshape,GRU\n",
        "from keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from inspect import signature\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjA26ceLvVZw"
      },
      "source": [
        "def main():\n",
        "    print(\"Loading datasets...\")\n",
        "    train = pd.read_csv(\"/content/gdrive/My Drive/exoTrain.csv\", encoding= \"ISO-8859-1\") \n",
        "    test = pd.read_csv(\"/content/gdrive/My Drive/exoTest.csv\", encoding= \"ISO-8859-1\") \n",
        "    x_train = train.drop('LABEL', axis=1)\n",
        "    x_test = test.drop('LABEL', axis=1)\n",
        "    y_train = train.LABEL\n",
        "    y_test = test.LABEL\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train).reshape((-1,1))-1\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(y_test).reshape((-1,1))-1 \n",
        "    \n",
        "    x_train = np.append(x_train, np.flip(x_train[0:37,:], axis=-1), axis=0)\n",
        "    y_train = np.append(y_train, y_train[0:37]).reshape((-1,1)) \n",
        "    x_test = np.append(x_test, np.flip(x_test[0:5,:], axis=-1), axis=0)\n",
        "    y_test = np.append(y_test, y_test[0:5]).reshape((-1,1))\n",
        "        \n",
        "    x_train = ((x_train - np.mean(x_train, axis=1).reshape(-1,1)) / np.std(x_train, axis=1).reshape(-1,1))\n",
        "    x_test = ((x_test - np.mean(x_test, axis=1).reshape(-1,1)) / np.std(x_test, axis=1).reshape(-1,1))\n",
        "    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],-1)\n",
        "    print(\"x_test shape\",x_test.shape)\n",
        "    print(\"y_test\",y_test.shape)\n",
        " \n",
        "    model = Sequential()  \n",
        "    model.add(LSTM(100,input_shape=(3197,1),return_sequences=True))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(LSTM(100,return_sequences=True))\n",
        "    model.add(Dropout(.1))\n",
        "    model.add(LSTM(100,return_sequences=False))\n",
        "    model.add(Dropout(.1))\n",
        "    model.add(Dense(1,activation=\"sigmoid\"))\n",
        "    \n",
        "    def shuffle_in_unison(a, b):    \n",
        "      rng_state = np.random.get_state()\n",
        "      np.random.shuffle(a)\n",
        "      np.random.set_state(rng_state)\n",
        "      np.random.shuffle(b)\n",
        "    \n",
        "    def batch_generator(x_train, y_train, batch_size=32):\n",
        "        half_batch = batch_size // 2\n",
        "        x_batch = np.empty((batch_size, x_train.shape[1], 1), dtype='float32') \n",
        "        y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32') \n",
        " \n",
        "        while True:\n",
        "            pos_idx = np.where(y_train[:,0] == 1)[0]\n",
        "            neg_idx = np.where(y_train[:,0] == 0)[0]\n",
        "            \n",
        "            np.random.shuffle(pos_idx)\n",
        "            np.random.shuffle(neg_idx)\n",
        " \n",
        "            x_batch[:half_batch] = x_train[pos_idx[:half_batch]].reshape(half_batch,x_train.shape[1],-1)\n",
        "            x_batch[half_batch:] = x_train[neg_idx[half_batch:batch_size]].reshape(half_batch,x_train.shape[1],-1)\n",
        "            y_batch[:half_batch] = y_train[pos_idx[:half_batch]]\n",
        "            y_batch[half_batch:] = y_train[neg_idx[half_batch:batch_size]]\n",
        "            shuffle_in_unison(x_batch,y_batch)\n",
        "            yield x_batch, y_batch\n",
        " \n",
        "    model.compile(optimizer=Adam(1e-5), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "    hist = model.fit_generator(batch_generator(x_train, y_train, 32),validation_data=(x_test, y_test),verbose=0, epochs=5,steps_per_epoch=x_train.shape[0]//32)\n",
        " \n",
        "    model.compile(optimizer=Adam(4e-5), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "    hist = model.fit_generator(batch_generator(x_train, y_train, 32),validation_data=(x_test, y_test),verbose=2, epochs=50,steps_per_epoch=x_train.shape[0]//32)\n",
        " \n",
        "    model_json = model.to_json()\n",
        "    with open(\"/content/gdrive/My Drive/LSTM_model.json\", \"w\") as  json_file:\n",
        "      json_file.write(model_json)\n",
        "    model.save_weights(\"/content/gdrive/My Drive/LSTM_model.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "    plt.plot(hist.history['loss'], color='b',label='loss')\n",
        "    plt.plot(hist.history['val_loss'], color='r',label='validation loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    plt.plot(hist.history['accuracy'], color='b',label='accuracy')\n",
        "    plt.plot(hist.history['val_accuracy'], color='r',label='validation accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"Make predictions for training data\")\n",
        "    shuffle_in_unison(x_train,y_train)\n",
        "    y_pred = model.predict(x_train.reshape(x_train.shape[0],x_train.shape[1],-1))[:,0]\n",
        "    pred = np.empty((1,len(y_pred)), dtype=object)\n",
        "    pred = np.where(y_pred>=0.5, 1, 0)\n",
        "    y_train = np.reshape(y_train,len(y_train))\n",
        "    pred = np.reshape(pred,len(pred))\n",
        "    \n",
        "    print(\"Create confusion matrix for training data\")\n",
        "    print('Validation for training data:')\n",
        "    conf_matrix = pd.crosstab(y_train, pred)\n",
        "    print(conf_matrix)\n",
        "    \n",
        "    accuracy = accuracy_score(y_train, pred)\n",
        "    precision = precision_score(y_train, pred)\n",
        "    recall = recall_score(y_train, pred)\n",
        "    fbeta = fbeta_score(y_train, pred, 1)\n",
        "    print('Accuracy: %.3f Precision: %.3f Recall: %.3f F_beta: %.3f' % (accuracy, precision, recall, fbeta))\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(y_train, y_pred, pos_label=1)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    print('Area under precision-recall-curve: %.3f' % (auc_pr))\n",
        "    step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
        "    plt.step(recall, precision, color='b', alpha=0.2,\n",
        "             where='post')\n",
        "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.show()\n",
        " \n",
        "    shuffle_in_unison(x_test,y_test)\n",
        "    y_pred = model.predict(x_test)[:,0] \n",
        "    pred = np.empty((1,len(y_pred)), dtype=object)\n",
        "    pred = np.where(y_pred>=0.5, 1, 0)\n",
        "    y_test = np.reshape(y_test,len(y_test))\n",
        "    pred = np.reshape(pred,len(pred))\n",
        "    \n",
        " \n",
        "    print('Validation for test data:')\n",
        "    conf_matrix = pd.crosstab(y_test, pred)\n",
        "    print(conf_matrix)\n",
        " \n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    fbeta = fbeta_score(y_test, pred, 1)\n",
        "    print('Accuracy: %.3f Precision: %.3f Recall: %.3f F_beta: %.3f'% (accuracy, precision, recall, fbeta))\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred, pos_label=1)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    print('Area under precision-recall-curve: %.3f' % (auc_pr))\n",
        "    step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
        "    plt.step(recall, precision, color='b', alpha=0.2,where='post')\n",
        "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SjTiKAPhOZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b9e8d65-99e2-44e4-9169-d2d2eb07303b"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print(\"In main\")\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In main\n",
            "Loading datasets...\n",
            "x_test shape (575, 3197, 1)\n",
            "y_test (575, 1)\n",
            "Epoch 1/50\n",
            "160/160 - 58s - loss: 0.6589 - accuracy: 0.5992 - val_loss: 0.6568 - val_accuracy: 0.7739\n",
            "Epoch 2/50\n",
            "160/160 - 53s - loss: 0.6548 - accuracy: 0.5992 - val_loss: 0.6340 - val_accuracy: 0.7948\n",
            "Epoch 3/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX1P2b_w8lH-",
        "outputId": "697c2597-36f1-44ea-b66c-b0da1769a9e5"
      },
      "source": [
        "json_file = open('/content/gdrive/My Drive/LSTM_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(\"/content/gdrive/My Drive/LSTM_model.h5\") \n",
        "print(\"Loaded model from disk\")\n",
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 3197, 100)         40800     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3197, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 3197, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3197, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 201,701\n",
            "Trainable params: 201,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}